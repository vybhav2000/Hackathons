{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597897454931",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import string\n",
    "import seaborn as sns\n",
    "import plotly.express as ex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID                                              TITLE  \\\n0   1        Reconstructing Subject-Specific Effect Maps   \n1   2                 Rotation Invariance Neural Network   \n2   3  Spherical polyharmonics and Poisson kernels fo...   \n3   4  A finite element approximation for the stochas...   \n4   5  Comparative study of Discrete Wavelet Transfor...   \n5   6  On maximizing the fundamental frequency of the...   \n\n                                            ABSTRACT  Computer Science  \\\n0    Predictive models allow subject-specific inf...                 1   \n1    Rotation invariance and translation invarian...                 1   \n2    We introduce and develop the notion of spher...                 0   \n3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n5    Let $\\Omega \\subset \\mathbb{R}^n$ be a bound...                 0   \n\n   Physics  Mathematics  Statistics  Quantitative Biology  \\\n0        0            0           0                     0   \n1        0            0           0                     0   \n2        0            1           0                     0   \n3        0            1           0                     0   \n4        0            0           1                     0   \n5        0            1           0                     0   \n\n   Quantitative Finance  \n0                     0  \n1                     0  \n2                     0  \n3                     0  \n4                     0  \n5                     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TITLE</th>\n      <th>ABSTRACT</th>\n      <th>Computer Science</th>\n      <th>Physics</th>\n      <th>Mathematics</th>\n      <th>Statistics</th>\n      <th>Quantitative Biology</th>\n      <th>Quantitative Finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Rotation Invariance Neural Network</td>\n      <td>Rotation invariance and translation invarian...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n      <td>We introduce and develop the notion of spher...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>A finite element approximation for the stochas...</td>\n      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Comparative study of Discrete Wavelet Transfor...</td>\n      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>On maximizing the fundamental frequency of the...</td>\n      <td>Let $\\Omega \\subset \\mathbb{R}^n$ be a bound...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'  Let $\\\\Omega \\\\subset \\\\mathbb{R}^n$ be a bounded domain satisfying a\\nHayman-type asymmetry condition, and let $ D $ be an arbitrary bounded domain\\nreferred to as \"obstacle\". We are interested in the behaviour of the first\\nDirichlet eigenvalue $ \\\\lambda_1(\\\\Omega \\\\setminus (x+D)) $. First, we prove an\\nupper bound on $ \\\\lambda_1(\\\\Omega \\\\setminus (x+D)) $ in terms of the distance\\nof the set $ x+D $ to the set of maximum points $ x_0 $ of the first Dirichlet\\nground state $ \\\\phi_{\\\\lambda_1} > 0 $ of $ \\\\Omega $. In short, a direct\\ncorollary is that if \\\\begin{equation} \\\\mu_\\\\Omega := \\\\max_{x}\\\\lambda_1(\\\\Omega\\n\\\\setminus (x+D)) \\\\end{equation} is large enough in terms of $ \\\\lambda_1(\\\\Omega)\\n$, then all maximizer sets $ x+D $ of $ \\\\mu_\\\\Omega $ are close to each maximum\\npoint $ x_0 $ of $ \\\\phi_{\\\\lambda_1} $.\\nSecond, we discuss the distribution of $ \\\\phi_{\\\\lambda_1(\\\\Omega)} $ and the\\npossibility to inscribe wavelength balls at a given point in $ \\\\Omega $.\\nFinally, we specify our observations to convex obstacles $ D $ and show that\\nif $ \\\\mu_\\\\Omega $ is sufficiently large with respect to $ \\\\lambda_1(\\\\Omega) $,\\nthen all maximizers $ x+D $ of $ \\\\mu_\\\\Omega $ contain all maximum points $ x_0\\n$ of $ \\\\phi_{\\\\lambda_1(\\\\Omega)} $.\\n'"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train.iloc[5]['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    s=[]\n",
    "    for w in x.split():\n",
    "        if w.lower() not in stop:\n",
    "            s.append(w)\n",
    "    s=' '.join(s)\n",
    "    url=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    k=url.sub(r'',s)\n",
    "    html=re.compile(r'<.*?>')\n",
    "    k=html.sub(r'',k)\n",
    "    k=re.sub('\\n',' ',k)\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    k=k.translate(table)\n",
    "    return k.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'let omega subset mathbbrn bounded domain satisfying haymantype asymmetry condition let   arbitrary bounded domain referred obstacle interested behaviour first dirichlet eigenvalue  lambda1omega setminus xd  first prove upper bound  lambda1omega setminus xd  terms distance set  xd  set maximum points  x0  first dirichlet ground state  philambda1  0   omega  short direct corollary beginequation muomega  maxxlambda1omega setminus xd endequation large enough terms  lambda1omega  maximizer sets  xd   muomega  close maximum point  x0   philambda1  second discuss distribution  philambda1omega  possibility inscribe wavelength balls given point  omega  finally specify observations convex obstacles   show  muomega  sufficiently large respect  lambda1omega  maximizers  xd   muomega  contain maximum points  x0   philambda1omega '"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "clean(train.iloc[5]['ABSTRACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ABSTRACT']=train['ABSTRACT'].apply(clean)\n",
    "test['ABSTRACT']=test['ABSTRACT'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          ID                                              TITLE  \\\n0          1        Reconstructing Subject-Specific Effect Maps   \n1          2                 Rotation Invariance Neural Network   \n2          3  Spherical polyharmonics and Poisson kernels fo...   \n3          4  A finite element approximation for the stochas...   \n4          5  Comparative study of Discrete Wavelet Transfor...   \n...      ...                                                ...   \n20967  20968  Contemporary machine learning: a guide for pra...   \n20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n20969  20970  Analysing Soccer Games with Clustering and Con...   \n20970  20971  On the Efficient Simulation of the Left-Tail o...   \n20971  20972   Why optional stopping is a problem for Bayesians   \n\n                                                ABSTRACT  Computer Science  \\\n0      predictive models allow subjectspecific infere...                 1   \n1      rotation invariance translation invariance gre...                 1   \n2      introduce develop notion spherical polyharmoni...                 0   \n3      stochastic landaulifshitzgilbert llg equation ...                 0   \n4      fouriertransform infrared ftir spectra samples...                 1   \n...                                                  ...               ...   \n20967  machine learning finding increasingly broad ap...                 1   \n20968  polycrystalline diamond coatings grown cemente...                 0   \n20969  present new approach identifying situations be...                 1   \n20970  sum lognormal variates encountered many challe...                 0   \n20971  recently optional stopping subject debate baye...                 0   \n\n       Physics  Mathematics  Statistics  Quantitative Biology  \\\n0            0            0           0                     0   \n1            0            0           0                     0   \n2            0            1           0                     0   \n3            0            1           0                     0   \n4            0            0           1                     0   \n...        ...          ...         ...                   ...   \n20967        1            0           0                     0   \n20968        1            0           0                     0   \n20969        0            0           0                     0   \n20970        0            1           1                     0   \n20971        0            1           1                     0   \n\n       Quantitative Finance  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n...                     ...  \n20967                     0  \n20968                     0  \n20969                     0  \n20970                     0  \n20971                     0  \n\n[20972 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TITLE</th>\n      <th>ABSTRACT</th>\n      <th>Computer Science</th>\n      <th>Physics</th>\n      <th>Mathematics</th>\n      <th>Statistics</th>\n      <th>Quantitative Biology</th>\n      <th>Quantitative Finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>predictive models allow subjectspecific infere...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Rotation Invariance Neural Network</td>\n      <td>rotation invariance translation invariance gre...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n      <td>introduce develop notion spherical polyharmoni...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>A finite element approximation for the stochas...</td>\n      <td>stochastic landaulifshitzgilbert llg equation ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Comparative study of Discrete Wavelet Transfor...</td>\n      <td>fouriertransform infrared ftir spectra samples...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20967</th>\n      <td>20968</td>\n      <td>Contemporary machine learning: a guide for pra...</td>\n      <td>machine learning finding increasingly broad ap...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20968</th>\n      <td>20969</td>\n      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n      <td>polycrystalline diamond coatings grown cemente...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20969</th>\n      <td>20970</td>\n      <td>Analysing Soccer Games with Clustering and Con...</td>\n      <td>present new approach identifying situations be...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20970</th>\n      <td>20971</td>\n      <td>On the Efficient Simulation of the Left-Tail o...</td>\n      <td>sum lognormal variates encountered many challe...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20971</th>\n      <td>20972</td>\n      <td>Why optional stopping is a problem for Bayesians</td>\n      <td>recently optional stopping subject debate baye...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20972 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train[['ABSTRACT']]\n",
    "y=train[cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                ABSTRACT\n0      predictive models allow subjectspecific infere...\n1      rotation invariance translation invariance gre...\n2      introduce develop notion spherical polyharmoni...\n3      stochastic landaulifshitzgilbert llg equation ...\n4      fouriertransform infrared ftir spectra samples...\n...                                                  ...\n20967  machine learning finding increasingly broad ap...\n20968  polycrystalline diamond coatings grown cemente...\n20969  present new approach identifying situations be...\n20970  sum lognormal variates encountered many challe...\n20971  recently optional stopping subject debate baye...\n\n[20972 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABSTRACT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>predictive models allow subjectspecific infere...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rotation invariance translation invariance gre...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>introduce develop notion spherical polyharmoni...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>stochastic landaulifshitzgilbert llg equation ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fouriertransform infrared ftir spectra samples...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20967</th>\n      <td>machine learning finding increasingly broad ap...</td>\n    </tr>\n    <tr>\n      <th>20968</th>\n      <td>polycrystalline diamond coatings grown cemente...</td>\n    </tr>\n    <tr>\n      <th>20969</th>\n      <td>present new approach identifying situations be...</td>\n    </tr>\n    <tr>\n      <th>20970</th>\n      <td>sum lognormal variates encountered many challe...</td>\n    </tr>\n    <tr>\n      <th>20971</th>\n      <td>recently optional stopping subject debate baye...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20972 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Computer Science  Physics  Mathematics  Statistics  \\\n0                     1        0            0           0   \n1                     1        0            0           0   \n2                     0        0            1           0   \n3                     0        0            1           0   \n4                     1        0            0           1   \n...                 ...      ...          ...         ...   \n20967                 1        1            0           0   \n20968                 0        1            0           0   \n20969                 1        0            0           0   \n20970                 0        0            1           1   \n20971                 0        0            1           1   \n\n       Quantitative Biology  Quantitative Finance  \n0                         0                     0  \n1                         0                     0  \n2                         0                     0  \n3                         0                     0  \n4                         0                     0  \n...                     ...                   ...  \n20967                     0                     0  \n20968                     0                     0  \n20969                     0                     0  \n20970                     0                     0  \n20971                     0                     0  \n\n[20972 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Computer Science</th>\n      <th>Physics</th>\n      <th>Mathematics</th>\n      <th>Statistics</th>\n      <th>Quantitative Biology</th>\n      <th>Quantitative Finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20967</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20968</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20969</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20970</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20971</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20972 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", tol=0.001 ..................\n[CV] ... C=20, class_weight=None, penalty=l2, tol=0.001, total=   2.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.001 ..................\n[CV] ... C=20, class_weight=None, penalty=l2, tol=0.001, total=   1.7s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.001 ..................\n[CV] ... C=20, class_weight=None, penalty=l2, tol=0.001, total=   2.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.001 ..................\n[CV] ... C=20, class_weight=None, penalty=l2, tol=0.001, total=   1.7s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.001 ..................\n[CV] ... C=20, class_weight=None, penalty=l2, tol=0.001, total=   2.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.01 ...................\n[CV] .... C=20, class_weight=None, penalty=l2, tol=0.01, total=   1.5s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.01 ...................\n[CV] .... C=20, class_weight=None, penalty=l2, tol=0.01, total=   1.5s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.01 ...................\n[CV] .... C=20, class_weight=None, penalty=l2, tol=0.01, total=   1.6s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.01 ...................\n[CV] .... C=20, class_weight=None, penalty=l2, tol=0.01, total=   1.1s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.01 ...................\n[CV] .... C=20, class_weight=None, penalty=l2, tol=0.01, total=   1.8s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.0001 .................\n[CV] .. C=20, class_weight=None, penalty=l2, tol=0.0001, total=   2.1s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.0001 .................\n[CV] .. C=20, class_weight=None, penalty=l2, tol=0.0001, total=   1.8s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.0001 .................\n[CV] .. C=20, class_weight=None, penalty=l2, tol=0.0001, total=   2.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.0001 .................\n[CV] .. C=20, class_weight=None, penalty=l2, tol=0.0001, total=   1.8s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.0001 .................\n[CV] .. C=20, class_weight=None, penalty=l2, tol=0.0001, total=   2.2s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.1 ....................\n[CV] ..... C=20, class_weight=None, penalty=l2, tol=0.1, total=   1.4s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.1 ....................\n[CV] ..... C=20, class_weight=None, penalty=l2, tol=0.1, total=   1.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.1 ....................\n[CV] ..... C=20, class_weight=None, penalty=l2, tol=0.1, total=   1.1s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.1 ....................\n[CV] ..... C=20, class_weight=None, penalty=l2, tol=0.1, total=   1.0s\n[CV] C=20, class_weight=None, penalty=l2, tol=0.1 ....................\n[CV] ..... C=20, class_weight=None, penalty=l2, tol=0.1, total=   1.3s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l1, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.001, total=   2.5s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.001, total=   2.5s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.001, total=   3.0s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.001, total=   2.7s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.001 ..............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.001, total=   2.4s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.01, total=   2.4s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.01, total=   2.1s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.01, total=   2.6s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.01, total=   1.9s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.01 ...............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.01, total=   1.7s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.7s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.4s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.9s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.8s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.0001 .............\n[CV]  C=20, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.4s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l2, tol=0.1, total=   1.3s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l2, tol=0.1, total=   1.3s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l2, tol=0.1, total=   1.4s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l2, tol=0.1, total=   1.6s\n[CV] C=20, class_weight=balanced, penalty=l2, tol=0.1 ................\n[CV] . C=20, class_weight=balanced, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l1, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l2, tol=0.001, total=   1.9s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l2, tol=0.001, total=   2.0s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l2, tol=0.001, total=   2.5s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l2, tol=0.001, total=   2.4s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.001 .................\n[CV] .. C=100, class_weight=None, penalty=l2, tol=0.001, total=   2.5s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l2, tol=0.01, total=   1.6s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l2, tol=0.01, total=   1.5s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l2, tol=0.01, total=   2.1s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l2, tol=0.01, total=   2.1s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.01 ..................\n[CV] ... C=100, class_weight=None, penalty=l2, tol=0.01, total=   1.9s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l2, tol=0.0001, total=   2.7s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l2, tol=0.0001, total=   2.6s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l2, tol=0.0001, total=   3.1s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l2, tol=0.0001, total=   2.9s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.0001 ................\n[CV] . C=100, class_weight=None, penalty=l2, tol=0.0001, total=   2.8s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l2, tol=0.1, total=   0.9s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l2, tol=0.1, total=   0.8s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=None, penalty=l2, tol=0.1 ...................\n[CV] .... C=100, class_weight=None, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.01, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.0001, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l1, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l1, tol=0.1, total=   0.0s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.001, total=   2.6s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.001, total=   2.6s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.001, total=   2.4s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.001, total=   2.7s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.001 .............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.001, total=   2.7s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.01, total=   2.2s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.01, total=   2.0s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.01, total=   1.9s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.01, total=   1.9s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.01 ..............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.01, total=   2.0s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.9s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.0001, total=   3.0s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.0001, total=   2.7s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.0001, total=   3.0s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.0001 ............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.0001, total=   3.1s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.1, total=   1.3s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.1, total=   1.1s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.1, total=   1.2s\n[CV] C=100, class_weight=balanced, penalty=l2, tol=0.1 ...............\n[CV]  C=100, class_weight=balanced, penalty=l2, tol=0.1, total=   1.1s\n[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed:  7.5min finished\n"
    }
   ],
   "source": [
    "params={'penalty':['l1','l2'],'C': [0.001,0.1,1,2,5,10,20,100],'tol':[0.001,0.01,0.0001,0.1],'class_weight':[None,'balanced']}\n",
    "model=OneVsRestClassifier(LinearSVC(),n_jobs=1)\n",
    "svc=LogisticRegression()\n",
    "grid=GridSearchCV(svc,params,verbose=2)\n",
    "tf=TfidfVectorizer()\n",
    "X_train1=tf.fit_transform(X['ABSTRACT'])\n",
    "X_test=tf.transform(test['ABSTRACT'])\n",
    "for category in cats:\n",
    "    print('... Processing {}'.format(category))\n",
    "    grid.fit(X_train1, y[category])\n",
    "    prediction = grid.predict(X_test)\n",
    "    sub[category]=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "... Processing Computer Science\n... Processing Physics\n... Processing Mathematics\n... Processing Statistics\n... Processing Quantitative Biology\n... Processing Quantitative Finance\n"
    }
   ],
   "source": [
    "params={'penalty':['l1','l2'],'C': [0.001,0.1,1,2,5,10,20,100,1000],'tol':[0.001,0.01,0.0001,0.1],'class_weight':[None,'balanced']}\n",
    "model=OneVsRestClassifier(LogisticRegression(C=2,tol=0.001,class_weight='balanced',penalty='l2'),n_jobs=1)\n",
    "tf=TfidfVectorizer()\n",
    "X_train1=tf.fit_transform(X['ABSTRACT'])\n",
    "X_test=tf.transform(test['ABSTRACT'])\n",
    "for category in cats:\n",
    "    print('... Processing {}'.format(category))\n",
    "    model.fit(X_train1, y[category])\n",
    "    prediction = model.predict(X_test)\n",
    "    sub[category]=prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'C': 2, 'class_weight': 'balanced', 'penalty': 'l2', 'tol': 0.001}"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "X_train1=tf.fit_transform(X_train['ABSTRACT'])\n",
    "X_val1=tf.transform(X_val['ABSTRACT'])\n",
    "X_test=tf.transform(test['ABSTRACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<14680x73312 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1019452 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame(columns=['ID','Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['ID']=test['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         ID  Computer Science  Physics  Mathematics  Statistics  \\\n0     20973                 0        0            0           1   \n1     20974                 0        1            0           0   \n2     20975                 1        0            0           0   \n3     20976                 0        1            0           0   \n4     20977                 1        0            0           0   \n...     ...               ...      ...          ...         ...   \n8984  29957                 1        0            0           0   \n8985  29958                 1        0            1           0   \n8986  29959                 1        0            0           1   \n8987  29960                 1        0            0           1   \n8988  29961                 1        0            0           0   \n\n      Quantitative Biology  Quantitative Finance  \n0                        0                     0  \n1                        0                     0  \n2                        0                     0  \n3                        0                     0  \n4                        0                     0  \n...                    ...                   ...  \n8984                     0                     0  \n8985                     0                     0  \n8986                     1                     0  \n8987                     0                     0  \n8988                     0                     0  \n\n[8989 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Computer Science</th>\n      <th>Physics</th>\n      <th>Mathematics</th>\n      <th>Statistics</th>\n      <th>Quantitative Biology</th>\n      <th>Quantitative Finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20973</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20974</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20975</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20976</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20977</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8984</th>\n      <td>29957</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8985</th>\n      <td>29958</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8986</th>\n      <td>29959</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8987</th>\n      <td>29960</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8988</th>\n      <td>29961</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8989 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('pred9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}